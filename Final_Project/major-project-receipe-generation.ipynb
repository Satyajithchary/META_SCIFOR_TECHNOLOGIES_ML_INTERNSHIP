{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9265809,"sourceType":"datasetVersion","datasetId":5607118},{"sourceId":9314229,"sourceType":"datasetVersion","datasetId":5641166}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Importing Libraries**","metadata":{"_uuid":"427b8ad4-95ef-4a3b-82c6-9128c59c34c8","_cell_guid":"9f248970-c52d-4e40-8b6d-6a8ebc300e41","trusted":true}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow as tf\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"16bce920-d750-4ad6-a9e0-70d6af80e2ed","_cell_guid":"2b6ddeb2-e57f-4b33-be10-0054b2d96694","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-04T06:11:17.053562Z","iopub.execute_input":"2024-09-04T06:11:17.054196Z","iopub.status.idle":"2024-09-04T06:11:17.060120Z","shell.execute_reply.started":"2024-09-04T06:11:17.054160Z","shell.execute_reply":"2024-09-04T06:11:17.059070Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Download necessary NLTK data\nnltk.download('punkt', quiet=True)\nnltk.download('stopwords', quiet=True)","metadata":{"_uuid":"e07c8dca-73e7-4830-ac30-ccba4a65ee8a","_cell_guid":"3d749d38-7113-409d-ade4-f63e9cb98097","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-04T06:11:21.077174Z","iopub.execute_input":"2024-09-04T06:11:21.078008Z","iopub.status.idle":"2024-09-04T06:11:21.084765Z","shell.execute_reply.started":"2024-09-04T06:11:21.077967Z","shell.execute_reply":"2024-09-04T06:11:21.083839Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"# 1. Data Exploration and Preprocessing","metadata":{"_uuid":"95f96401-86a9-45c7-93a0-012c3a152177","_cell_guid":"19c3b6e7-2853-497b-a750-232887100a91","trusted":true}},{"cell_type":"code","source":"def load_and_preprocess_data(file_path):\n    # Load the dataset\n    df = pd.read_csv('/kaggle/input/recipenlg-dataset/full_dataset.csv')\n    \n    print(\"Columns in the dataset:\", df.columns.tolist())\n    \n    # Check if 'Directions' column exists, if not, try to find a similar column\n    directions_column = 'Directions'\n    if 'Directions' not in df.columns:\n        possible_columns = [col for col in df.columns if 'direction' in col.lower() or 'instruction' in col.lower()]\n        if possible_columns:\n            directions_column = possible_columns[0]\n            print(f\"Using '{directions_column}' as the directions column.\")\n        else:\n            raise ValueError(\"Could not find a suitable column for recipe directions.\")\n    \n    # Data Cleaning\n    df.dropna(subset=[directions_column], inplace=True)\n    df.drop_duplicates(subset=[directions_column], inplace=True)\n    \n    # Text Processing\n    stop_words = set(stopwords.words('english'))\n    \n    def preprocess_text(text):\n        # Convert to lowercase\n        text = text.lower()\n        # Remove special characters and digits\n        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n        # Tokenize\n        tokens = text.split()\n        # Remove stop words\n        tokens = [word for word in tokens if word not in stop_words]\n        return ' '.join(tokens)\n    \n    df['processed_directions'] = df[directions_column].apply(preprocess_text)\n    \n    return df","metadata":{"_uuid":"900f2015-937b-4fe3-8033-d2b8c830c617","_cell_guid":"84bfd8e2-7330-47bc-b44a-c9eb49fa68f4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-04T06:11:22.402037Z","iopub.execute_input":"2024-09-04T06:11:22.402739Z","iopub.status.idle":"2024-09-04T06:11:22.412169Z","shell.execute_reply.started":"2024-09-04T06:11:22.402698Z","shell.execute_reply":"2024-09-04T06:11:22.411216Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def load_and_preprocess_data(file_path, sample_fraction=0.05):\n    # Load the dataset\n    df = pd.read_csv('/kaggle/input/recipenlg-dataset/full_dataset.csv')\n    \n    # Sample a fraction of the data\n    df = df.sample(frac=sample_fraction, random_state=42)\n    \n    print(\"Columns in the dataset:\", df.columns.tolist())\n    \n    # Check if 'Directions' column exists, if not, try to find a similar column\n    directions_column = 'Directions'\n    if 'Directions' not in df.columns:\n        possible_columns = [col for col in df.columns if 'direction' in col.lower() or 'instruction' in col.lower()]\n        if possible_columns:\n            directions_column = possible_columns[0]\n            \n    # Data Cleaning\n    df.dropna(subset=[directions_column], inplace=True)\n    df.drop_duplicates(subset=[directions_column], inplace=True)\n    \n    # Text Processing\n    stop_words = set(stopwords.words('english'))\n    \n    def preprocess_text(text):\n        # Convert to lowercase\n        text = text.lower()\n        # Remove special characters and digits\n        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n        # Tokenize\n        tokens = text.split()\n        # Remove stop words\n        tokens = [word for word in tokens if word not in stop_words]\n        return ' '.join(tokens)\n    \n    df['processed_directions'] = df[directions_column].apply(preprocess_text)\n    \n    return df\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T06:11:28.276899Z","iopub.execute_input":"2024-09-04T06:11:28.277270Z","iopub.status.idle":"2024-09-04T06:11:28.286813Z","shell.execute_reply.started":"2024-09-04T06:11:28.277234Z","shell.execute_reply":"2024-09-04T06:11:28.285841Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Preparation","metadata":{"_uuid":"9e1eecfd-3810-4480-b175-918faa53debc","_cell_guid":"79a93cc4-91a8-41e4-b0fc-0d0d69777d40","trusted":true}},{"cell_type":"code","source":"def prepare_sequences(texts, max_sequence_length, max_words):\n    tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n    tokenizer.fit_on_texts(texts)\n    \n    sequences = tokenizer.texts_to_sequences(texts)\n    padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='pre', truncating='pre')\n    \n    return padded_sequences, tokenizer","metadata":{"_uuid":"e9ee82bd-ad10-463e-a01b-a5a5eefdc81d","_cell_guid":"bbe06d57-e0a1-4a69-8a87-9b5e80aa0c75","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-04T06:11:29.798133Z","iopub.execute_input":"2024-09-04T06:11:29.798986Z","iopub.status.idle":"2024-09-04T06:11:29.804323Z","shell.execute_reply.started":"2024-09-04T06:11:29.798943Z","shell.execute_reply":"2024-09-04T06:11:29.803415Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model Building","metadata":{"_uuid":"cf9a819d-b030-46a6-bc14-6d8449f0fa72","_cell_guid":"198acfbc-21ea-4f2c-9212-e61e31a3c1a4","trusted":true}},{"cell_type":"code","source":"def build_model(vocab_size, embedding_dim, max_sequence_length):\n    model = Sequential([\n        Embedding(vocab_size, embedding_dim, input_length=max_sequence_length),\n        LSTM(128, return_sequences=True),\n        Dropout(0.2),\n        LSTM(128),\n        Dropout(0.2),\n        Dense(vocab_size, activation='softmax')\n    ])\n    \n    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n    return model","metadata":{"_uuid":"6c74cdf2-dd07-4a39-a3fd-a2dec5425f79","_cell_guid":"8b503b44-ed1c-4581-964f-be7ebdb24fc0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-04T06:11:31.117928Z","iopub.execute_input":"2024-09-04T06:11:31.118802Z","iopub.status.idle":"2024-09-04T06:11:31.124408Z","shell.execute_reply.started":"2024-09-04T06:11:31.118762Z","shell.execute_reply":"2024-09-04T06:11:31.123503Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# 4. Training","metadata":{"_uuid":"b621b679-ada6-4d8b-a018-591e5a27ce0b","_cell_guid":"3a272c34-c11f-4c9d-bd6d-d51c8ebb541f","trusted":true}},{"cell_type":"code","source":"def train_model(model, X_train, y_train, epochs, batch_size):\n    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n    return history","metadata":{"_uuid":"7b5200aa-e5cf-4fe7-9cc1-19bf05d8278d","_cell_guid":"c0745252-0616-4a14-b178-2dc0db7539a5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-04T06:11:32.390345Z","iopub.execute_input":"2024-09-04T06:11:32.391028Z","iopub.status.idle":"2024-09-04T06:11:32.395734Z","shell.execute_reply.started":"2024-09-04T06:11:32.390988Z","shell.execute_reply":"2024-09-04T06:11:32.394674Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# 5. Recipe Generation","metadata":{"_uuid":"1c1f2cfd-2d27-4cd1-aeda-bdf03ac55382","_cell_guid":"4472e1a4-beef-4c8f-90c0-0f2cb1fb3267","trusted":true}},{"cell_type":"code","source":"def generate_recipe(model, tokenizer, seed_text, max_sequence_length, num_words):\n    generated_text = seed_text\n    for _ in range(num_words):\n        encoded = tokenizer.texts_to_sequences([generated_text])[0]\n        encoded = pad_sequences([encoded], maxlen=max_sequence_length, padding='pre')\n        \n        pred = model.predict(encoded, verbose=0)\n        pred_word = tokenizer.index_word[np.argmax(pred)]\n        \n        generated_text += ' ' + pred_word\n        \n        if pred_word == '.':\n            break\n    \n    return generated_text","metadata":{"_uuid":"381858f6-45ea-4043-af3e-4cc2f5ad3e5c","_cell_guid":"2a5c3fc1-4296-4ea1-92b1-ae0779f4d0fc","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-04T06:11:33.544974Z","iopub.execute_input":"2024-09-04T06:11:33.545688Z","iopub.status.idle":"2024-09-04T06:11:33.551677Z","shell.execute_reply.started":"2024-09-04T06:11:33.545649Z","shell.execute_reply":"2024-09-04T06:11:33.550684Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Visualization function","metadata":{"_uuid":"8179487f-c021-4464-8d87-c69b9c7c058a","_cell_guid":"a9f7fff3-b889-4f49-9cd2-e1b11c23ba9e","trusted":true}},{"cell_type":"code","source":"def plot_training_history(history):\n    plt.figure(figsize=(12, 4))\n    \n    plt.subplot(121)\n    plt.plot(history.history['loss'], label='Training Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Model Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.subplot(122)\n    plt.plot(history.history['accuracy'], label='Training Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Model Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.savefig('training_history.png')\n    plt.close()","metadata":{"_uuid":"a151f795-afd6-4b2e-b288-f97ad2f53dbf","_cell_guid":"7f083eb6-021d-4074-abd4-d7e878db4b37","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-04T06:11:34.673622Z","iopub.execute_input":"2024-09-04T06:11:34.674000Z","iopub.status.idle":"2024-09-04T06:11:34.681738Z","shell.execute_reply.started":"2024-09-04T06:11:34.673964Z","shell.execute_reply":"2024-09-04T06:11:34.680690Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Main execution","metadata":{"_uuid":"ca507bb0-30b1-47f0-aac5-c72bfd5ad540","_cell_guid":"e0458c2d-9ba2-472c-995e-c76cbf765b5c","trusted":true}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Parameters\n    file_path = '/kaggle/input/recipenlg-dataset/full_dataset.csv'\n    max_sequence_length = 100\n    max_words = 10000\n    embedding_dim = 100\n    epochs = 30\n    batch_size = 128\n    \n    try:\n        # 1. Data Exploration and Preprocessing\n        df = load_and_preprocess_data(file_path)\n        \n        # Print some information about the dataset\n        print(\"\\nDataset Info:\")\n        print(df.info())\n        print(\"\\nSample processed directions:\")\n        print(df['processed_directions'].head())\n        \n        # 2. Data Preparation\n        padded_sequences, tokenizer = prepare_sequences(df['processed_directions'], max_sequence_length, max_words)\n        \n        # Prepare input sequences and target words\n        X = padded_sequences[:, :-1]\n        y = padded_sequences[:, -1]\n        y = tf.keras.utils.to_categorical(y, num_classes=max_words)\n        \n        # Split the data\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n        \n        # 3. Model Building\n        model = build_model(max_words, embedding_dim, max_sequence_length-1)\n        \n        \n        # 4. Training\n        history = train_model(model, X_train, y_train, epochs, batch_size)\n        \n        # Visualize training history\n        plot_training_history(history)\n        print(\"Training history plot saved as 'training_history.png'\")\n        \n        # 5. Evaluation and Recipe Generation\n        # Evaluate the model\n        test_loss, test_accuracy = model.evaluate(X_test, y_test)\n        print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n        \n        # Generate a recipe\n        seed_text = \"to make chicken soup\"\n        generated_recipe = generate_recipe(model, tokenizer, seed_text, max_sequence_length-1, 50)\n        print(\"\\nGenerated Recipe:\")\n        print(generated_recipe)\n        \n        # 6. Documentation and Reporting\n        # Save the model\n        model.save('recipe_generation_model.h5')\n        \n        # Save the tokenizer\n        import pickle\n        with open('tokenizer.pickle', 'wb') as handle:\n            pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n        \n        print(\"\\nModel and tokenizer saved. Don't forget to write a detailed report!\")\n        \n    except Exception as e:\n        print(f\"An error occurred: {str(e)}\")\n        print(\"Please check the dataset and column names.\")","metadata":{"_uuid":"fcb638cf-deb6-4ee8-b691-4cbeb73302bd","_cell_guid":"57912791-5e95-4401-a087-6da913026f0e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-04T06:11:35.786303Z","iopub.execute_input":"2024-09-04T06:11:35.787001Z","iopub.status.idle":"2024-09-04T06:19:28.807144Z","shell.execute_reply.started":"2024-09-04T06:11:35.786960Z","shell.execute_reply":"2024-09-04T06:19:28.806217Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Columns in the dataset: ['Unnamed: 0', 'title', 'ingredients', 'directions', 'link', 'source', 'NER']\n\nDataset Info:\n<class 'pandas.core.frame.DataFrame'>\nIndex: 111368 entries, 2015528 to 333594\nData columns (total 8 columns):\n #   Column                Non-Null Count   Dtype \n---  ------                --------------   ----- \n 0   Unnamed: 0            111368 non-null  int64 \n 1   title                 111368 non-null  object\n 2   ingredients           111368 non-null  object\n 3   directions            111368 non-null  object\n 4   link                  111368 non-null  object\n 5   source                111368 non-null  object\n 6   NER                   111368 non-null  object\n 7   processed_directions  111368 non-null  object\ndtypes: int64(1), object(7)\nmemory usage: 7.6+ MB\nNone\n\nSample processed directions:\n2015528    remove tenderloin steak score meat combine rem...\n1608734    combine ingredients slow cooker quarts bury ch...\n778500     cook carrots cut crosswise inch pieces add but...\n1334975    mix dry ingredients bowl add crisco cut dough ...\n116562     mix press baking pan approximately x inch bake...\nName: processed_directions, dtype: object\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.0744 - loss: 6.4374 - val_accuracy: 0.1012 - val_loss: 5.5738\nEpoch 2/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.1091 - loss: 5.4502 - val_accuracy: 0.1528 - val_loss: 5.1555\nEpoch 3/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.1566 - loss: 5.0283 - val_accuracy: 0.1943 - val_loss: 4.7967\nEpoch 4/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.2004 - loss: 4.6603 - val_accuracy: 0.2330 - val_loss: 4.5322\nEpoch 5/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.2375 - loss: 4.3750 - val_accuracy: 0.2610 - val_loss: 4.3531\nEpoch 6/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.2633 - loss: 4.1783 - val_accuracy: 0.2777 - val_loss: 4.2460\nEpoch 7/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.2815 - loss: 4.0277 - val_accuracy: 0.2911 - val_loss: 4.1526\nEpoch 8/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.3002 - loss: 3.8776 - val_accuracy: 0.3066 - val_loss: 4.0660\nEpoch 9/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.3107 - loss: 3.7746 - val_accuracy: 0.3144 - val_loss: 4.0032\nEpoch 10/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.3192 - loss: 3.6611 - val_accuracy: 0.3242 - val_loss: 3.9602\nEpoch 11/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.3308 - loss: 3.5452 - val_accuracy: 0.3314 - val_loss: 3.9149\nEpoch 12/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.3425 - loss: 3.4456 - val_accuracy: 0.3372 - val_loss: 3.8772\nEpoch 13/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.3525 - loss: 3.3538 - val_accuracy: 0.3419 - val_loss: 3.8611\nEpoch 14/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.3560 - loss: 3.2941 - val_accuracy: 0.3453 - val_loss: 3.8513\nEpoch 15/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.3649 - loss: 3.2041 - val_accuracy: 0.3499 - val_loss: 3.8392\nEpoch 16/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.3684 - loss: 3.1388 - val_accuracy: 0.3520 - val_loss: 3.8398\nEpoch 17/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.3771 - loss: 3.0895 - val_accuracy: 0.3544 - val_loss: 3.8326\nEpoch 18/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.3810 - loss: 3.0074 - val_accuracy: 0.3560 - val_loss: 3.8436\nEpoch 19/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.3892 - loss: 2.9584 - val_accuracy: 0.3587 - val_loss: 3.8425\nEpoch 20/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.3962 - loss: 2.8830 - val_accuracy: 0.3633 - val_loss: 3.8675\nEpoch 21/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.4026 - loss: 2.8407 - val_accuracy: 0.3643 - val_loss: 3.8774\nEpoch 22/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.4117 - loss: 2.7764 - val_accuracy: 0.3647 - val_loss: 3.8957\nEpoch 23/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.4160 - loss: 2.7292 - val_accuracy: 0.3668 - val_loss: 3.9126\nEpoch 24/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.4194 - loss: 2.6883 - val_accuracy: 0.3657 - val_loss: 3.9533\nEpoch 25/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.4300 - loss: 2.6356 - val_accuracy: 0.3661 - val_loss: 3.9651\nEpoch 26/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.4383 - loss: 2.5957 - val_accuracy: 0.3666 - val_loss: 3.9814\nEpoch 27/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.4407 - loss: 2.5490 - val_accuracy: 0.3683 - val_loss: 4.0128\nEpoch 28/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.4498 - loss: 2.5053 - val_accuracy: 0.3674 - val_loss: 4.0269\nEpoch 29/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.4585 - loss: 2.4688 - val_accuracy: 0.3695 - val_loss: 4.0610\nEpoch 30/30\n\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.4615 - loss: 2.4224 - val_accuracy: 0.3687 - val_loss: 4.0745\nTraining history plot saved as 'training_history.png'\n\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.3707 - loss: 4.0407\n\nTest Accuracy: 0.3681\n\nGenerated Recipe:\nto make chicken soup bowl smooth serves people <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>\n\nModel and tokenizer saved. Don't forget to write a detailed report!\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install streamlit\n","metadata":{"_uuid":"6392fd0e-64f5-440b-a06c-68395686369b","_cell_guid":"e0e0a280-2336-47ed-b141-57c186114d61","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-04T06:21:31.125449Z","iopub.execute_input":"2024-09-04T06:21:31.125852Z","iopub.status.idle":"2024-09-04T06:21:47.335165Z","shell.execute_reply.started":"2024-09-04T06:21:31.125817Z","shell.execute_reply":"2024-09-04T06:21:47.333769Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting streamlit\n  Downloading streamlit-1.38.0-py2.py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.4.0)\nRequirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.8.2)\nRequirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.2.4)\nRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.1.7)\nRequirement already satisfied: numpy<3,>=1.20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.26.4)\nRequirement already satisfied: packaging<25,>=20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (21.3)\nRequirement already satisfied: pandas<3,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.2.2)\nRequirement already satisfied: pillow<11,>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (9.5.0)\nRequirement already satisfied: protobuf<6,>=3.20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.20.3)\nRequirement already satisfied: pyarrow>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (16.1.0)\nRequirement already satisfied: requests<3,>=2.27 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.32.3)\nRequirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (13.7.1)\nRequirement already satisfied: tenacity<9,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.3.0)\nRequirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.10.2)\nRequirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.12.2)\nRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.1.43)\nCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.4.1)\nCollecting watchdog<5,>=2.1.5 (from streamlit)\n  Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl.metadata (38 kB)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.22.0)\nRequirement already satisfied: narwhals>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (1.4.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25,>=20->streamlit) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\nDownloading streamlit-1.38.0-py2.py3-none-any.whl (8.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl (82 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\nSuccessfully installed pydeck-0.9.1 streamlit-1.38.0 watchdog-4.0.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import pickle\n\nwith open('tokenizer.pkl', 'wb') as f:\n    pickle.dump(tokenizer, f)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T06:24:19.390308Z","iopub.execute_input":"2024-09-04T06:24:19.391106Z","iopub.status.idle":"2024-09-04T06:24:19.440145Z","shell.execute_reply.started":"2024-09-04T06:24:19.391061Z","shell.execute_reply":"2024-09-04T06:24:19.439371Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import streamlit as st\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport pickle\n\n# Load the model and tokenizer\nmodel = tf.keras.models.load_model('/kaggle/working/recipe_generation_model.h5')\nwith open('tokenizer.pkl', 'rb') as f:\n    tokenizer = pickle.load(f)\n\nmax_sequence_len = 100  # Set this to the value used during training\n\nst.title('Recipe Generation App')\n\ninput_text = st.text_input('Enter the start of your recipe:')\n\nif st.button('Generate Recipe'):\n    if input_text:\n        # Preprocess the input text\n        token_list = tokenizer.texts_to_sequences([input_text])[0]\n        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n\n        # Generate the recipe\n        predicted = model.predict_classes(token_list, verbose=0)\n\n        # Decode the prediction to text\n        output_word = \"\"\n        for word, index in tokenizer.word_index.items():\n            if index == predicted:\n                output_word = word\n                break\n\n        st.write('Generated Recipe:', input_text + \" \" + output_word)\n    else:\n        st.write('Please enter some text to start the recipe.')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T06:24:24.527450Z","iopub.execute_input":"2024-09-04T06:24:24.527844Z","iopub.status.idle":"2024-09-04T06:24:24.767523Z","shell.execute_reply.started":"2024-09-04T06:24:24.527809Z","shell.execute_reply":"2024-09-04T06:24:24.766634Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"2024-09-04 06:24:24.678 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-09-04 06:24:24.753 \n  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n  command:\n\n    streamlit run /opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n2024-09-04 06:24:24.754 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-09-04 06:24:24.755 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-09-04 06:24:24.756 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-09-04 06:24:24.757 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-09-04 06:24:24.757 Session state does not function when running a script without `streamlit run`\n2024-09-04 06:24:24.758 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-09-04 06:24:24.759 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-09-04 06:24:24.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-09-04 06:24:24.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-09-04 06:24:24.761 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-09-04 06:24:24.762 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","output_type":"stream"}]},{"cell_type":"code","source":"!streamlit run /opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py","metadata":{"execution":{"iopub.status.busy":"2024-09-04T06:27:01.243653Z","iopub.execute_input":"2024-09-04T06:27:01.244114Z","iopub.status.idle":"2024-09-04T06:30:19.516802Z","shell.execute_reply.started":"2024-09-04T06:27:01.244071Z","shell.execute_reply":"2024-09-04T06:30:19.515543Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"\nCollecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n\u001b[0m\n\u001b[0m\n\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n\u001b[0m\n\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.19.2.2:8501\u001b[0m\n\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.230.2.226:8501\u001b[0m\n\u001b[0m\n^C\n\u001b[34m  Stopping...\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"!streamlit run app.py\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T06:24:57.569560Z","iopub.execute_input":"2024-09-04T06:24:57.570503Z","iopub.status.idle":"2024-09-04T06:24:59.433265Z","shell.execute_reply.started":"2024-09-04T06:24:57.570421Z","shell.execute_reply":"2024-09-04T06:24:59.432041Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Usage: streamlit run [OPTIONS] TARGET [ARGS]...\nTry 'streamlit run --help' for help.\n\nError: Invalid value: File does not exist: app.py\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
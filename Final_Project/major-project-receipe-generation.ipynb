{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9265809,"sourceType":"datasetVersion","datasetId":5607118}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Importing Libraries**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow as tf\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nimport matplotlib.pyplot as plt","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download necessary NLTK data\nnltk.download('punkt', quiet=True)\nnltk.download('stopwords', quiet=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-28T16:24:47.633246Z","iopub.execute_input":"2024-08-28T16:24:47.633923Z","iopub.status.idle":"2024-08-28T16:24:47.784733Z","shell.execute_reply.started":"2024-08-28T16:24:47.633883Z","shell.execute_reply":"2024-08-28T16:24:47.783845Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"# 1. Data Exploration and Preprocessing\n","metadata":{}},{"cell_type":"code","source":"def load_and_preprocess_data(file_path):\n    # Load the dataset\n    df = pd.read_csv('/kaggle/input/recipenlg-dataset/full_dataset.csv')\n    \n    print(\"Columns in the dataset:\", df.columns.tolist())\n    \n    # Check if 'Directions' column exists, if not, try to find a similar column\n    directions_column = 'Directions'\n    if 'Directions' not in df.columns:\n        possible_columns = [col for col in df.columns if 'direction' in col.lower() or 'instruction' in col.lower()]\n        if possible_columns:\n            directions_column = possible_columns[0]\n            print(f\"Using '{directions_column}' as the directions column.\")\n        else:\n            raise ValueError(\"Could not find a suitable column for recipe directions.\")\n    \n    # Data Cleaning\n    df.dropna(subset=[directions_column], inplace=True)\n    df.drop_duplicates(subset=[directions_column], inplace=True)\n    \n    # Text Processing\n    stop_words = set(stopwords.words('english'))\n    \n    def preprocess_text(text):\n        # Convert to lowercase\n        text = text.lower()\n        # Remove special characters and digits\n        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n        # Tokenize\n        tokens = text.split()\n        # Remove stop words\n        tokens = [word for word in tokens if word not in stop_words]\n        return ' '.join(tokens)\n    \n    df['processed_directions'] = df[directions_column].apply(preprocess_text)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2024-08-28T16:25:04.350694Z","iopub.execute_input":"2024-08-28T16:25:04.351588Z","iopub.status.idle":"2024-08-28T16:25:04.360898Z","shell.execute_reply.started":"2024-08-28T16:25:04.351545Z","shell.execute_reply":"2024-08-28T16:25:04.359844Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Preparation\n","metadata":{}},{"cell_type":"code","source":"def prepare_sequences(texts, max_sequence_length, max_words):\n    tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n    tokenizer.fit_on_texts(texts)\n    \n    sequences = tokenizer.texts_to_sequences(texts)\n    padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='pre', truncating='pre')\n    \n    return padded_sequences, tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-08-28T16:25:14.790176Z","iopub.execute_input":"2024-08-28T16:25:14.791034Z","iopub.status.idle":"2024-08-28T16:25:14.796498Z","shell.execute_reply.started":"2024-08-28T16:25:14.790993Z","shell.execute_reply":"2024-08-28T16:25:14.795543Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model Building\n","metadata":{}},{"cell_type":"code","source":"def build_model(vocab_size, embedding_dim, max_sequence_length):\n    model = Sequential([\n        Embedding(vocab_size, embedding_dim, input_length=max_sequence_length),\n        LSTM(128, return_sequences=True),\n        Dropout(0.2),\n        LSTM(128),\n        Dropout(0.2),\n        Dense(vocab_size, activation='softmax')\n    ])\n    \n    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-08-28T16:25:26.495002Z","iopub.execute_input":"2024-08-28T16:25:26.496097Z","iopub.status.idle":"2024-08-28T16:25:26.502180Z","shell.execute_reply.started":"2024-08-28T16:25:26.496050Z","shell.execute_reply":"2024-08-28T16:25:26.501189Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# 4. Training\n","metadata":{}},{"cell_type":"code","source":"def train_model(model, X_train, y_train, epochs, batch_size):\n    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n    return history","metadata":{"execution":{"iopub.status.busy":"2024-08-28T16:25:35.415562Z","iopub.execute_input":"2024-08-28T16:25:35.415976Z","iopub.status.idle":"2024-08-28T16:25:35.421093Z","shell.execute_reply.started":"2024-08-28T16:25:35.415938Z","shell.execute_reply":"2024-08-28T16:25:35.420102Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# 5. Recipe Generation\n","metadata":{}},{"cell_type":"code","source":"def generate_recipe(model, tokenizer, seed_text, max_sequence_length, num_words):\n    generated_text = seed_text\n    for _ in range(num_words):\n        encoded = tokenizer.texts_to_sequences([generated_text])[0]\n        encoded = pad_sequences([encoded], maxlen=max_sequence_length, padding='pre')\n        \n        pred = model.predict(encoded, verbose=0)\n        pred_word = tokenizer.index_word[np.argmax(pred)]\n        \n        generated_text += ' ' + pred_word\n        \n        if pred_word == '.':\n            break\n    \n    return generated_text","metadata":{"execution":{"iopub.status.busy":"2024-08-28T16:25:46.589882Z","iopub.execute_input":"2024-08-28T16:25:46.590326Z","iopub.status.idle":"2024-08-28T16:25:46.597761Z","shell.execute_reply.started":"2024-08-28T16:25:46.590284Z","shell.execute_reply":"2024-08-28T16:25:46.596625Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Visualization function\n","metadata":{}},{"cell_type":"code","source":"def plot_training_history(history):\n    plt.figure(figsize=(12, 4))\n    \n    plt.subplot(121)\n    plt.plot(history.history['loss'], label='Training Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Model Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.subplot(122)\n    plt.plot(history.history['accuracy'], label='Training Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Model Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.savefig('training_history.png')\n    plt.close()","metadata":{"execution":{"iopub.status.busy":"2024-08-28T16:25:59.597085Z","iopub.execute_input":"2024-08-28T16:25:59.597519Z","iopub.status.idle":"2024-08-28T16:25:59.605160Z","shell.execute_reply.started":"2024-08-28T16:25:59.597478Z","shell.execute_reply":"2024-08-28T16:25:59.604202Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Main execution\n","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Parameters\n    file_path = '/kaggle/input/recipenlg-dataset/full_dataset.csv'\n    max_sequence_length = 100\n    max_words = 10000\n    embedding_dim = 100\n    epochs = 50\n    batch_size = 128\n    \n    try:\n        # 1. Data Exploration and Preprocessing\n        df = load_and_preprocess_data(file_path)\n        \n        # Print some information about the dataset\n        print(\"\\nDataset Info:\")\n        print(df.info())\n        print(\"\\nSample processed directions:\")\n        print(df['processed_directions'].head())\n        \n        # 2. Data Preparation\n        padded_sequences, tokenizer = prepare_sequences(df['processed_directions'], max_sequence_length, max_words)\n        \n        # Prepare input sequences and target words\n        X = padded_sequences[:, :-1]\n        y = padded_sequences[:, -1]\n        y = tf.keras.utils.to_categorical(y, num_classes=max_words)\n        \n        # Split the data\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n        \n        # 3. Model Building\n        model = build_model(max_words, embedding_dim, max_sequence_length-1)\n        \n        # 4. Training\n        history = train_model(model, X_train, y_train, epochs, batch_size)\n        \n        # Visualize training history\n        plot_training_history(history)\n        print(\"Training history plot saved as 'training_history.png'\")\n        \n        # 5. Evaluation and Recipe Generation\n        # Evaluate the model\n        test_loss, test_accuracy = model.evaluate(X_test, y_test)\n        print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n        \n        # Generate a recipe\n        seed_text = \"to make chicken soup\"\n        generated_recipe = generate_recipe(model, tokenizer, seed_text, max_sequence_length-1, 50)\n        print(\"\\nGenerated Recipe:\")\n        print(generated_recipe)\n        \n        # 6. Documentation and Reporting\n        # Save the model\n        model.save('recipe_generation_model.h5')\n        \n        # Save the tokenizer\n        import pickle\n        with open('tokenizer.pickle', 'wb') as handle:\n            pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n        \n        print(\"\\nModel and tokenizer saved. Don't forget to write a detailed report!\")\n        \n    except Exception as e:\n        print(f\"An error occurred: {str(e)}\")\n        print(\"Please check the dataset and column names.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-28T16:26:43.596464Z","iopub.execute_input":"2024-08-28T16:26:43.597283Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Columns in the dataset: ['Unnamed: 0', 'title', 'ingredients', 'directions', 'link', 'source', 'NER']\nUsing 'directions' as the directions column.\n\nDataset Info:\n<class 'pandas.core.frame.DataFrame'>\nIndex: 2211644 entries, 0 to 2231141\nData columns (total 8 columns):\n #   Column                Dtype \n---  ------                ----- \n 0   Unnamed: 0            int64 \n 1   title                 object\n 2   ingredients           object\n 3   directions            object\n 4   link                  object\n 5   source                object\n 6   NER                   object\n 7   processed_directions  object\ndtypes: int64(1), object(7)\nmemory usage: 151.9+ MB\nNone\n\nSample processed directions:\n0    heavy quart saucepan mix brown sugar nuts evap...\n1    place chipped beef bottom baking dish place ch...\n2    slow cooker combine ingredients cover cook low...\n3    boil debone chicken put bite size pieces avera...\n4    combine first four ingredients press x inch un...\nName: processed_directions, dtype: object\n","output_type":"stream"}]}]}